{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to normalize column names and standardize 'gmt_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column_names(df, filepath):\n",
    "    df = df.copy()\n",
    "    # Replace non-alphanumeric characters with underscores\n",
    "    df.columns = df.columns.str.replace(r\"[^\\w\\s]\", \"_\", regex=True)\n",
    "    # Replace any whitespace with a single underscore\n",
    "    df.columns = df.columns.str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "    # Convert to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "    # Replace multiple underscores with a single underscore\n",
    "    df.columns = df.columns.str.replace(r\"_+\", \"_\", regex=True)\n",
    "    # Remove leading and trailing underscores\n",
    "    df.columns = df.columns.str.strip('_')\n",
    "    # Map known time columns to 'gmt_time'\n",
    "    time_column_variations = ['gmt_time', 'time', 'date_time', 'datetime', 'timestamp', 'gmt']\n",
    "    found_time_column = False\n",
    "    for col in time_column_variations:\n",
    "        if col in df.columns:\n",
    "            df.rename(columns={col: 'gmt_time'}, inplace=True)\n",
    "            found_time_column = True\n",
    "            break\n",
    "    if not found_time_column:\n",
    "        print(f\"Warning: No recognized time column found in {filepath}. Please check the column names.\")\n",
    "    # Print columns for debugging\n",
    "    print(f\"Columns after normalization for {filepath}: {df.columns.tolist()}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load and preprocess a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_dataset(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.replace('No Data Available', np.nan, inplace=True)\n",
    "    df = normalize_column_names(df, filepath)\n",
    "    if 'gmt_time' in df.columns:\n",
    "        df['gmt_time'] = pd.to_datetime(df['gmt_time'], errors='coerce')\n",
    "    else:\n",
    "        raise KeyError(f\"The required column 'gmt_time' is missing in the dataset {filepath}.\")\n",
    "    # Convert all columns except 'gmt_time' to numeric\n",
    "    cols = df.columns.drop('gmt_time')\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and preprocess datasets using the defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing datasets...\n",
      "Columns after normalization for /Users/sravansridhar/Desktop/Edp_datathon/data/balancing_data.csv: ['gmt_time', 'system_price_eso_outturn_gb_mwh', 'niv_outturn_ve_long_gb_mw', 'bm_bid_acceptances_total_gb_mw', 'bm_offer_acceptances_total_gb_mw', 'total_bsad_volume_turn_up_gb_mw', 'total_bsad_volume_turn_down_gb_mw', 'total_bsad_volume_total_gb_mw', 'intraday_volume_epex_outturn_apx_mid_gb_mwh']\n",
      "Columns after normalization for /Users/sravansridhar/Desktop/Edp_datathon/data/demand_load_data.csv: ['gmt_time', 'loss_of_load_probability_latest_gb', 'actual_total_load_gb_mw', 'demand_outturn_itsdo_gb_mw']\n",
      "Columns after normalization for /Users/sravansridhar/Desktop/Edp_datathon/data/generation_data.csv: ['gmt_time', 'actual_aggregated_generation_by_type_biomass_gb_mw', 'actual_aggregated_generation_by_type_fossil_gas_gb_mw', 'actual_aggregated_generation_by_type_fossil_hard_coal_gb_mw', 'actual_aggregated_generation_by_type_fossil_oil_gb_mw', 'actual_aggregated_generation_by_type_hydro_pumped_storage_gb_mw', 'actual_aggregated_generation_by_type_hydro_run_of_river_and_poundage_gb_mw', 'actual_aggregated_generation_by_type_nuclear_gb_mw', 'actual_aggregated_generation_by_type_solar_gb_mw', 'actual_aggregated_generation_by_type_wind_onshore_gb_mw', 'actual_aggregated_generation_by_type_wind_offshore_gb_mw']\n",
      "Columns after normalization for /Users/sravansridhar/Desktop/Edp_datathon/data/price_data.csv: ['gmt_time', 'day_ahead_price_epex_half_hourly_local_gb_lc_mwh', 'intraday_price_epex_outturn_apx_mid_gb_mwh']\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading and preprocessing datasets...\")\n",
    "balancing_data = load_and_preprocess_dataset('../data/balancing_data.csv')\n",
    "demand_load_data = load_and_preprocess_dataset('../data/demand_load_data.csv')\n",
    "generation_data = load_and_preprocess_dataset('../data/generation_data.csv')\n",
    "price_data = load_and_preprocess_dataset('../data/price_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge datasets on 'gmt_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging datasets...\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging datasets...\")\n",
    "data_frames = [balancing_data, demand_load_data, generation_data, price_data]\n",
    "merged_data = data_frames[0]\n",
    "for df in data_frames[1:]:\n",
    "    merged_data = pd.merge(merged_data, df, on='gmt_time', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4n/xlvp5dd530zgvp5yzcjmsv400000gn/T/ipykernel_20997/630599973.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_data.fillna(method='ffill', inplace=True)\n",
      "/var/folders/4n/xlvp5dd530zgvp5yzcjmsv400000gn/T/ipykernel_20997/630599973.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_data.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Handling missing values...\")\n",
    "merged_data.sort_values('gmt_time', inplace=True)\n",
    "merged_data.dropna(subset=['gmt_time'], inplace=True)\n",
    "merged_data.fillna(method='ffill', inplace=True)\n",
    "merged_data.fillna(method='bfill', inplace=True)\n",
    "merged_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure all data types are numeric except 'gmt_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensuring data types are correct...\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensuring data types are correct...\")\n",
    "cols = merged_data.columns.drop('gmt_time')\n",
    "merged_data[cols] = merged_data[cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering...\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature engineering...\")\n",
    "# Add time-based features\n",
    "merged_data['hour'] = merged_data['gmt_time'].dt.hour\n",
    "merged_data['day_of_week'] = merged_data['gmt_time'].dt.dayofweek\n",
    "merged_data['month'] = merged_data['gmt_time'].dt.month\n",
    "merged_data['is_weekend'] = (merged_data['day_of_week'] >= 5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding lag features...\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding lag features...\")\n",
    "lag_features = ['system_price_eso_outturn_gb_mwh', 'niv_outturn_ve_long_gb_mw']\n",
    "for lag in [1, 24, 48]:  # Lag by 1 hour, 1 day, 2 days\n",
    "    for col in lag_features:\n",
    "        if col in merged_data.columns:\n",
    "            merged_data[f'{col}_lag_{lag}'] = merged_data[col].shift(lag)\n",
    "        else:\n",
    "            print(f\"Warning: Column {col} not found in merged_data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add rolling statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding rolling statistics...\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding rolling statistics...\")\n",
    "for window in [7, 30]:  # Weekly and monthly\n",
    "    for col in lag_features:\n",
    "        if col in merged_data.columns:\n",
    "            merged_data[f'{col}_rolling_mean_{window}'] = merged_data[col].rolling(window).mean()\n",
    "        else:\n",
    "            print(f\"Warning: Column {col} not found in merged_data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with NaN values created due to lags/rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining features and targets...\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining features and targets...\")\n",
    "X = merged_data.drop(columns=['gmt_time', 'system_price_eso_outturn_gb_mwh', 'niv_outturn_ve_long_gb_mw'])\n",
    "y_price = merged_data['system_price_eso_outturn_gb_mwh']\n",
    "y_niv = merged_data['niv_outturn_ve_long_gb_mw']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure there are no remaining non-numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying that all features are numeric...\n"
     ]
    }
   ],
   "source": [
    "print(\"Verifying that all features are numeric...\")\n",
    "non_numeric_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "if non_numeric_cols:\n",
    "    print(f\"Converting non-numeric columns to numeric: {non_numeric_cols}\")\n",
    "    X[non_numeric_cols] = X[non_numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    X.dropna(inplace=True)\n",
    "    y_price = y_price.loc[X.index]\n",
    "    y_niv = y_niv.loc[X.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a pipeline with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pipelines...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating pipelines...\")\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the preprocessing and modeling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(model):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining base models...\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining base models...\")\n",
    "# XGBoost parameters (CPU version)\n",
    "xgb_params = {\n",
    "    'random_state': 42,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_jobs': multiprocessing.cpu_count()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM parameters (CPU version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'random_state': 42,\n",
    "    'n_jobs': multiprocessing.cpu_count()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('rf', RandomForestRegressor(random_state=42, n_jobs=multiprocessing.cpu_count())),\n",
    "    ('gb', GradientBoostingRegressor(random_state=42)),\n",
    "    ('xgb', XGBRegressor(**xgb_params)),\n",
    "    ('lgbm', LGBMRegressor(**lgbm_params))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipelines for base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipelines = [(name, create_pipeline(model)) for name, model in base_models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define stacking regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining stacking regressors...\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining stacking regressors...\")\n",
    "stacking_regressor_price = StackingRegressor(\n",
    "    estimators=base_pipelines,\n",
    "    final_estimator=Ridge(),\n",
    "    passthrough=True,\n",
    "    n_jobs=multiprocessing.cpu_count()\n",
    ")\n",
    "stacking_regressor_niv = StackingRegressor(\n",
    "    estimators=base_pipelines,\n",
    "    final_estimator=Ridge(),\n",
    "    passthrough=True,\n",
    "    n_jobs=multiprocessing.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning for System Price model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting hyperparameter tuning for System Price model...\")\n",
    "param_distributions = {\n",
    "    'rf__model__n_estimators': [100, 200],\n",
    "    'rf__model__max_depth': [None, 10],\n",
    "    'gb__model__n_estimators': [100, 200],\n",
    "    'gb__model__learning_rate': [0.05, 0.1],\n",
    "    'xgb__model__n_estimators': [100, 200],\n",
    "    'xgb__model__learning_rate': [0.05, 0.1],\n",
    "    'lgbm__model__n_estimators': [100, 200],\n",
    "    'lgbm__model__learning_rate': [0.05, 0.1],\n",
    "    'final_estimator__alpha': [0.1, 1.0, 10.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to perform RandomizedSearchCV with multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_search(model, X, y, param_distributions, model_name):\n",
    "    print(f\"Performing hyperparameter tuning for {model_name}...\")\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=20,\n",
    "        cv=tscv,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        verbose=2,\n",
    "        n_jobs=multiprocessing.cpu_count(),\n",
    "        random_state=42\n",
    "    )\n",
    "    random_search.fit(X, y)\n",
    "    best_model = random_search.best_estimator_\n",
    "    print(f\"Best parameters for {model_name}: {random_search.best_params_}\")\n",
    "    # Save the best model\n",
    "    joblib.dump(best_model, f'pipeline_model_{model_name}.pkl')\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform hyperparameter tuning for System Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing hyperparameter tuning for price...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=11.0min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.1, xgb__model__n_estimators=100; total time=11.3min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=12.2min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time= 6.5min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=22.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=12.6min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.1, xgb__model__n_estimators=100; total time=24.5min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=24.6min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=25.1min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=11.0min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=17.8min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time= 9.8min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=36.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.1, xgb__model__n_estimators=100; total time=36.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=36.7min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=10.5min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=100, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time= 6.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=23.6min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=47.0min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=22.5min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=100, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=11.5min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.1, xgb__model__n_estimators=200; total time= 5.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=22.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=100, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=16.9min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=33.5min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.1, xgb__model__n_estimators=200; total time=10.4min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=18.7min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=33.0min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time= 5.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.1, xgb__model__n_estimators=200; total time=15.8min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=32.4min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=68.2min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=19.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time= 6.2min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=12.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.1, xgb__model__n_estimators=200; total time=20.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=12.2min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=17.8min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=42.9min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=17.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=19.0min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time= 5.1min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=43.0min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=18.8min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.1, xgb__model__n_estimators=200; total time=43.8min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=11.6min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 51.665461\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=11.1min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.732734\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.974401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 48.998987\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 52.572151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.048849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=16.9min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.056804\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=64.8min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=41.2min\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=64.0min\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=19.6min\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=16.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.224711\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.211854\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.1, xgb__model__n_estimators=200; total time=62.2min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 103.229078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 83.349966\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.268789\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=39.0min\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=24.8min\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=53.4min\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=27.7min\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=49.8min\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=38.6min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7463\n",
      "[LightGBM] [Info] Number of data points in the train set: 118272, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 87.648025\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7461\n",
      "[LightGBM] [Info] Number of data points in the train set: 94617, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 95.798078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7456\n",
      "[LightGBM] [Info] Number of data points in the train set: 94618, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 84.357161\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7463\n",
      "[LightGBM] [Info] Number of data points in the train set: 94618, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 91.492348\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7453\n",
      "[LightGBM] [Info] Number of data points in the train set: 94617, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 101.073622\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 94618, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 65.519146\n",
      "Best parameters for price: {'xgb__model__n_estimators': 200, 'xgb__model__learning_rate': 0.1, 'rf__model__n_estimators': 100, 'rf__model__max_depth': 10, 'lgbm__model__n_estimators': 200, 'lgbm__model__learning_rate': 0.05, 'gb__model__n_estimators': 100, 'gb__model__learning_rate': 0.1, 'final_estimator__alpha': 10.0}\n"
     ]
    }
   ],
   "source": [
    "best_model_price = perform_random_search(\n",
    "    stacking_regressor_price,\n",
    "    X,\n",
    "    y_price,\n",
    "    param_distributions,\n",
    "    'price'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform hyperparameter tuning for NIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning for NIV model...\n",
      "Performing hyperparameter tuning for niv...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.1, xgb__model__n_estimators=100; total time= 9.1min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time= 9.2min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=12.5min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time= 6.8min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=18.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=20.2min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.1, xgb__model__n_estimators=100; total time=20.3min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=12.8min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=25.3min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=11.4min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time= 8.7min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=18.3min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.1, xgb__model__n_estimators=100; total time=31.1min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=31.1min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time= 8.8min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=100, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time= 5.9min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=37.6min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=39.7min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=19.4min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=24.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=100, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=12.3min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.1, xgb__model__n_estimators=200; total time= 5.3min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=18.9min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=100, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=15.6min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=16.3min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.1, xgb__model__n_estimators=200; total time=11.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=29.2min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=35.3min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=28.5min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=59.3min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.1, xgb__model__n_estimators=200; total time=16.7min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time= 4.9min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=15.7min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time= 6.4min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.1, xgb__model__n_estimators=200; total time=16.5min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=12.3min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=12.6min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=36.7min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=18.0min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=18.1min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=16.2min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=35.9min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time= 5.6min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=16.4min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.1, xgb__model__n_estimators=200; total time=36.6min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=12.1min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 133.659058\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=100, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=57.0min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=11.2min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7462\n",
      "[LightGBM] [Info] Number of data points in the train set: 88704, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.236152\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7443\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 127.966509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7440\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 134.042424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23654, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 137.923679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7436\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.839347\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7431\n",
      "[LightGBM] [Info] Number of data points in the train set: 23655, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 138.523291\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=10, rf__model__n_estimators=100, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=16.6min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=35.5min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -25.957575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -11.633740\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=55.6min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 28.254306\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 70963, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.140849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 70964, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 14.376804\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=14.0min\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=34.7min\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.1, xgb__model__n_estimators=200; total time=55.0min\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=20.2min\n",
      "[CV] END final_estimator__alpha=10.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=10, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=25.3min\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.05, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=100, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=100; total time=46.9min\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=23.7min\n",
      "[CV] END final_estimator__alpha=1.0, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.1, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=43.6min\n",
      "[CV] END final_estimator__alpha=0.1, gb__model__learning_rate=0.1, gb__model__n_estimators=200, lgbm__model__learning_rate=0.05, lgbm__model__n_estimators=200, rf__model__max_depth=None, rf__model__n_estimators=200, xgb__model__learning_rate=0.05, xgb__model__n_estimators=200; total time=33.9min\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7463\n",
      "[LightGBM] [Info] Number of data points in the train set: 118272, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 15.748620\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7463\n",
      "[LightGBM] [Info] Number of data points in the train set: 94618, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 10.014753\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7456\n",
      "[LightGBM] [Info] Number of data points in the train set: 94618, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 39.026190\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7453\n",
      "[LightGBM] [Info] Number of data points in the train set: 94617, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 24.194325\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7461\n",
      "[LightGBM] [Info] Number of data points in the train set: 94617, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -14.946021\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 94618, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 20.453617\n",
      "Best parameters for niv: {'xgb__model__n_estimators': 200, 'xgb__model__learning_rate': 0.05, 'rf__model__n_estimators': 200, 'rf__model__max_depth': None, 'lgbm__model__n_estimators': 200, 'lgbm__model__learning_rate': 0.05, 'gb__model__n_estimators': 200, 'gb__model__learning_rate': 0.1, 'final_estimator__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting hyperparameter tuning for NIV model...\")\n",
    "best_model_niv = perform_random_search(\n",
    "    stacking_regressor_niv,\n",
    "    X,\n",
    "    y_niv,\n",
    "    param_distributions,\n",
    "    'niv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare features for October 1, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features for October 1, 2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4n/xlvp5dd530zgvp5yzcjmsv400000gn/T/ipykernel_20997/2431054851.py:3: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_oct1 = pd.date_range(start='2024-10-01 00:00:00', end='2024-10-01 23:30:00', freq='30T')\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing features for October 1, 2024...\")\n",
    "# Generate date range for October 1, 2024\n",
    "dates_oct1 = pd.date_range(start='2024-10-01 00:00:00', end='2024-10-01 23:30:00', freq='30T')\n",
    "october_1_features = pd.DataFrame({'gmt_time': dates_oct1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the same features as in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features for October 1, 2024...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating features for October 1, 2024...\")\n",
    "october_1_features['hour'] = october_1_features['gmt_time'].dt.hour\n",
    "october_1_features['day_of_week'] = october_1_features['gmt_time'].dt.dayofweek\n",
    "october_1_features['month'] = october_1_features['gmt_time'].dt.month\n",
    "october_1_features['is_weekend'] = (october_1_features['day_of_week'] >= 5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate lag and rolling features using historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating lag and rolling features using historical data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimating lag and rolling features using historical data...\")\n",
    "# Calculate historical averages for lag and rolling features\n",
    "historical_data = merged_data.copy()\n",
    "historical_data['time'] = historical_data['gmt_time'].dt.time\n",
    "october_1_features['time'] = october_1_features['gmt_time'].dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of features to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_estimate = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean values by time for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_features = historical_data.groupby('time')[features_to_estimate].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge mean features with october_1_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "october_1_features = pd.merge(october_1_features, mean_features, on='time', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "october_1_features.drop(columns=['time', 'gmt_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure no missing values in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values in October 1 features...\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for missing values in October 1 features...\")\n",
    "if october_1_features.isnull().values.any():\n",
    "    print(\"Filling missing values with historical means...\")\n",
    "    october_1_features.fillna(october_1_features.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict for October 1, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for October 1, 2024...\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting for October 1, 2024...\")\n",
    "# Load the pipelines\n",
    "best_model_price_loaded = joblib.load('pipeline_model_price.pkl')\n",
    "best_model_niv_loaded = joblib.load('pipeline_model_niv.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features: ['bm_bid_acceptances_total_gb_mw', 'bm_offer_acceptances_total_gb_mw', 'total_bsad_volume_turn_up_gb_mw', 'total_bsad_volume_turn_down_gb_mw', 'total_bsad_volume_total_gb_mw', 'intraday_volume_epex_outturn_apx_mid_gb_mwh', 'loss_of_load_probability_latest_gb', 'actual_total_load_gb_mw', 'demand_outturn_itsdo_gb_mw', 'actual_aggregated_generation_by_type_biomass_gb_mw', 'actual_aggregated_generation_by_type_fossil_gas_gb_mw', 'actual_aggregated_generation_by_type_fossil_hard_coal_gb_mw', 'actual_aggregated_generation_by_type_fossil_oil_gb_mw', 'actual_aggregated_generation_by_type_hydro_pumped_storage_gb_mw', 'actual_aggregated_generation_by_type_hydro_run_of_river_and_poundage_gb_mw', 'actual_aggregated_generation_by_type_nuclear_gb_mw', 'actual_aggregated_generation_by_type_solar_gb_mw', 'actual_aggregated_generation_by_type_wind_onshore_gb_mw', 'actual_aggregated_generation_by_type_wind_offshore_gb_mw', 'day_ahead_price_epex_half_hourly_local_gb_lc_mwh', 'intraday_price_epex_outturn_apx_mid_gb_mwh', 'hour', 'day_of_week', 'month', 'is_weekend', 'system_price_eso_outturn_gb_mwh_lag_1', 'niv_outturn_ve_long_gb_mw_lag_1', 'system_price_eso_outturn_gb_mwh_lag_24', 'niv_outturn_ve_long_gb_mw_lag_24', 'system_price_eso_outturn_gb_mwh_lag_48', 'niv_outturn_ve_long_gb_mw_lag_48', 'system_price_eso_outturn_gb_mwh_rolling_mean_7', 'niv_outturn_ve_long_gb_mw_rolling_mean_7', 'system_price_eso_outturn_gb_mwh_rolling_mean_30', 'niv_outturn_ve_long_gb_mw_rolling_mean_30']\n"
     ]
    }
   ],
   "source": [
    "# After defining X during training\n",
    "training_feature_columns = X.columns.tolist()\n",
    "print(\"Training Features:\", training_feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feature_columns = [\n",
    "    'bm_bid_acceptances_total_gb_mw',\n",
    "    'bm_offer_acceptances_total_gb_mw',\n",
    "    'total_bsad_volume_turn_up_gb_mw',\n",
    "    'total_bsad_volume_turn_down_gb_mw',\n",
    "    'total_bsad_volume_total_gb_mw',\n",
    "    'intraday_volume_epex_outturn_apx_mid_gb_mwh',\n",
    "    'loss_of_load_probability_latest_gb',\n",
    "    'actual_total_load_gb_mw',\n",
    "    'demand_outturn_itsdo_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_biomass_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_fossil_gas_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_fossil_hard_coal_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_fossil_oil_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_hydro_pumped_storage_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_hydro_run_of_river_and_poundage_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_nuclear_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_solar_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_wind_onshore_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_wind_offshore_gb_mw',\n",
    "    'day_ahead_price_epex_half_hourly_local_gb_lc_mwh',\n",
    "    'intraday_price_epex_outturn_apx_mid_gb_mwh',\n",
    "    'hour',\n",
    "    'day_of_week',\n",
    "    'month',\n",
    "    'is_weekend',\n",
    "    'system_price_eso_outturn_gb_mwh_lag_1',\n",
    "    'niv_outturn_ve_long_gb_mw_lag_1',\n",
    "    'system_price_eso_outturn_gb_mwh_lag_24',\n",
    "    'niv_outturn_ve_long_gb_mw_lag_24',\n",
    "    'system_price_eso_outturn_gb_mwh_lag_48',\n",
    "    'niv_outturn_ve_long_gb_mw_lag_48',\n",
    "    'system_price_eso_outturn_gb_mwh_rolling_mean_7',\n",
    "    'niv_outturn_ve_long_gb_mw_rolling_mean_7',\n",
    "    'system_price_eso_outturn_gb_mwh_rolling_mean_30',\n",
    "    'niv_outturn_ve_long_gb_mw_rolling_mean_30'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4n/xlvp5dd530zgvp5yzcjmsv400000gn/T/ipykernel_20997/792563929.py:2: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  dates_oct1 = pd.date_range(start='2024-10-01 00:00:00', end='2024-10-01 23:30:00', freq='30T')\n"
     ]
    }
   ],
   "source": [
    "# Generate date range for October 1, 2024 at 30-minute intervals\n",
    "dates_oct1 = pd.date_range(start='2024-10-01 00:00:00', end='2024-10-01 23:30:00', freq='30T')\n",
    "october_1_features = pd.DataFrame({'gmt_time': dates_oct1})\n",
    "\n",
    "# Create time-based features\n",
    "october_1_features['hour'] = october_1_features['gmt_time'].dt.hour\n",
    "october_1_features['day_of_week'] = october_1_features['gmt_time'].dt.dayofweek\n",
    "october_1_features['month'] = october_1_features['gmt_time'].dt.month\n",
    "october_1_features['is_weekend'] = (october_1_features['day_of_week'] >= 5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate historical means from the training data\n",
    "historical_means = merged_data.mean()\n",
    "\n",
    "# Define lag and rolling feature columns\n",
    "lag_features = ['system_price_eso_outturn_gb_mwh', 'niv_outturn_ve_long_gb_mw']\n",
    "lag_feature_cols = [f'{col}_lag_{lag}' for col in lag_features for lag in [1, 24, 48]]\n",
    "rolling_feature_cols = [f'{col}_rolling_mean_{window}' for col in lag_features for window in [7, 30]]\n",
    "\n",
    "# Assign historical mean values to lag features\n",
    "for col in lag_feature_cols:\n",
    "    october_1_features[col] = historical_means.get(col, np.nan)  # Use np.nan if the mean is not available\n",
    "\n",
    "# Assign historical mean values to rolling features\n",
    "for col in rolling_feature_cols:\n",
    "    october_1_features[col] = historical_means.get(col, np.nan)  # Use np.nan if the mean is not available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of original features from merged datasets used during training\n",
    "original_features = [\n",
    "    'bm_bid_acceptances_total_gb_mw',\n",
    "    'bm_offer_acceptances_total_gb_mw',\n",
    "    'total_bsad_volume_turn_up_gb_mw',\n",
    "    'total_bsad_volume_turn_down_gb_mw',\n",
    "    'total_bsad_volume_total_gb_mw',\n",
    "    'intraday_volume_epex_outturn_apx_mid_gb_mwh',\n",
    "    'loss_of_load_probability_latest_gb',\n",
    "    'actual_total_load_gb_mw',\n",
    "    'demand_outturn_itsdo_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_biomass_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_fossil_gas_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_fossil_hard_coal_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_fossil_oil_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_hydro_pumped_storage_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_hydro_run_of_river_and_poundage_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_nuclear_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_solar_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_wind_onshore_gb_mw',\n",
    "    'actual_aggregated_generation_by_type_wind_offshore_gb_mw',\n",
    "    'day_ahead_price_epex_half_hourly_local_gb_lc_mwh',\n",
    "    'intraday_price_epex_outturn_apx_mid_gb_mwh'\n",
    "]\n",
    "\n",
    "# Assign historical mean values to original features\n",
    "for col in original_features:\n",
    "    october_1_features[col] = historical_means.get(col, np.nan)  # Use np.nan if the mean is not available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "if october_1_features.isnull().values.any():\n",
    "    october_1_features.fillna(october_1_features.mean(), inplace=True)\n",
    "    print(\"Filled missing values with historical means.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'gmt_time' as it's not a feature used in the model\n",
    "october_1_features = october_1_features.drop(columns=['gmt_time'])\n",
    "\n",
    "# Ensure the order of columns matches the training data\n",
    "training_feature_columns = X.columns.tolist()\n",
    "october_1_features = october_1_features[training_feature_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature set for prediction:\n",
      "['bm_bid_acceptances_total_gb_mw', 'bm_offer_acceptances_total_gb_mw', 'total_bsad_volume_turn_up_gb_mw', 'total_bsad_volume_turn_down_gb_mw', 'total_bsad_volume_total_gb_mw', 'intraday_volume_epex_outturn_apx_mid_gb_mwh', 'loss_of_load_probability_latest_gb', 'actual_total_load_gb_mw', 'demand_outturn_itsdo_gb_mw', 'actual_aggregated_generation_by_type_biomass_gb_mw', 'actual_aggregated_generation_by_type_fossil_gas_gb_mw', 'actual_aggregated_generation_by_type_fossil_hard_coal_gb_mw', 'actual_aggregated_generation_by_type_fossil_oil_gb_mw', 'actual_aggregated_generation_by_type_hydro_pumped_storage_gb_mw', 'actual_aggregated_generation_by_type_hydro_run_of_river_and_poundage_gb_mw', 'actual_aggregated_generation_by_type_nuclear_gb_mw', 'actual_aggregated_generation_by_type_solar_gb_mw', 'actual_aggregated_generation_by_type_wind_onshore_gb_mw', 'actual_aggregated_generation_by_type_wind_offshore_gb_mw', 'day_ahead_price_epex_half_hourly_local_gb_lc_mwh', 'intraday_price_epex_outturn_apx_mid_gb_mwh', 'hour', 'day_of_week', 'month', 'is_weekend', 'system_price_eso_outturn_gb_mwh_lag_1', 'niv_outturn_ve_long_gb_mw_lag_1', 'system_price_eso_outturn_gb_mwh_lag_24', 'niv_outturn_ve_long_gb_mw_lag_24', 'system_price_eso_outturn_gb_mwh_lag_48', 'niv_outturn_ve_long_gb_mw_lag_48', 'system_price_eso_outturn_gb_mwh_rolling_mean_7', 'niv_outturn_ve_long_gb_mw_rolling_mean_7', 'system_price_eso_outturn_gb_mwh_rolling_mean_30', 'niv_outturn_ve_long_gb_mw_rolling_mean_30']\n"
     ]
    }
   ],
   "source": [
    "# Verify that all training features are present in the prediction data\n",
    "missing_features = set(training_feature_columns) - set(october_1_features.columns)\n",
    "extra_features = set(october_1_features.columns) - set(training_feature_columns)\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"Missing features in prediction data: {missing_features}\")\n",
    "    # Assign default values or handle as needed\n",
    "    for feature in missing_features:\n",
    "        october_1_features[feature] = historical_means.get(feature, 0)\n",
    "        print(f\"Assigned default value 0 to missing feature: {feature}\")\n",
    "\n",
    "if extra_features:\n",
    "    print(f\"Extra features in prediction data: {extra_features}\")\n",
    "    # Remove extra features if they are not needed\n",
    "    october_1_features = october_1_features.drop(columns=extra_features)\n",
    "    print(f\"Dropped extra features: {extra_features}\")\n",
    "\n",
    "# Final verification\n",
    "print(\"Final feature set for prediction:\")\n",
    "print(october_1_features.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'predictions_october_1_2024.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved pipelines\n",
    "best_model_price_loaded = joblib.load('pipeline_model_price.pkl')\n",
    "best_model_niv_loaded = joblib.load('pipeline_model_niv.pkl')\n",
    "\n",
    "# Make predictions\n",
    "october_1_predictions_price = best_model_price_loaded.predict(october_1_features)\n",
    "october_1_predictions_niv = best_model_niv_loaded.predict(october_1_features)\n",
    "\n",
    "# Create output DataFrame\n",
    "output = pd.DataFrame({\n",
    "    'GTM_TIME': dates_oct1,\n",
    "    'SYSTEM_PRICE': october_1_predictions_price,\n",
    "    'NIV_OUTTURN': october_1_predictions_niv\n",
    "})\n",
    "\n",
    "# Save predictions to CSV\n",
    "output.to_csv('predictions_october_1_2024.csv', index=False)\n",
    "print(\"Predictions saved to 'predictions_october_1_2024.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving predictions...\")\n",
    "output.to_csv('predictions_october_1_2024.csv', index=False)\n",
    "print(\"Predictions saved to 'predictions_october_1_2024.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model performance on the training set (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model performance on training data...\n",
      "Training RMSE for System Price: 36.8048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model performance on training data...\")\n",
    "y_pred_price = best_model_price_loaded.predict(X)\n",
    "rmse_price = mean_squared_error(y_price, y_pred_price, squared=False)\n",
    "print(f\"Training RMSE for System Price: {rmse_price:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE for NIV: 72.8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/ds_env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred_niv = best_model_niv_loaded.predict(X)\n",
    "rmse_niv = mean_squared_error(y_niv, y_pred_niv, squared=False)\n",
    "print(f\"Training RMSE for NIV: {rmse_niv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the merged data and features for Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder: /Users/sravansridhar/Desktop/Edp_datathon/notebooks/streamlit_assets\n",
      "Copied: pipeline_model_price.pkl to streamlit_assets/\n",
      "Copied: pipeline_model_niv.pkl to streamlit_assets/\n",
      "Warning: merged_data_processed.csv does not exist and was not copied.\n",
      "Copied: predictions_october_1_2024.csv to streamlit_assets/\n",
      "Warning: features.csv does not exist and was not copied.\n",
      "Warning: target_price.csv does not exist and was not copied.\n",
      "Warning: target_niv.csv does not exist and was not copied.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the name of the destination folder\n",
    "destination_folder = 'streamlit_assets'\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define the full path for the destination folder\n",
    "destination_path = os.path.join(current_dir, destination_folder)\n",
    "\n",
    "# List of files to copy to the Streamlit assets folder\n",
    "files_to_copy = [\n",
    "    'pipeline_model_price.pkl',\n",
    "    'pipeline_model_niv.pkl',\n",
    "    'merged_data_processed.csv',\n",
    "    'predictions_october_1_2024.csv',\n",
    "    'features.csv',\n",
    "    'target_price.csv',\n",
    "    'target_niv.csv',\n",
    "    # Add any additional files here\n",
    "    # 'additional_file.ext',\n",
    "]\n",
    "\n",
    "# Create the destination folder if it doesn't exist\n",
    "if not os.path.exists(destination_path):\n",
    "    os.makedirs(destination_path)\n",
    "    print(f\"Created folder: {destination_path}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {destination_path}\")\n",
    "\n",
    "# Copy each file to the destination folder\n",
    "for file in files_to_copy:\n",
    "    source_file = os.path.join(current_dir, file)\n",
    "    destination_file = os.path.join(destination_path, file)\n",
    "    \n",
    "    if os.path.exists(source_file):\n",
    "        shutil.copy(source_file, destination_file)\n",
    "        print(f\"Copied: {file} to {destination_folder}/\")\n",
    "    else:\n",
    "        print(f\"Warning: {file} does not exist and was not copied.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_data DataFrame is ready.\n",
      "Created folder: /Users/sravansridhar/Desktop/Edp_datathon/notebooks/streamlit_assets\n",
      "Saved 'merged_data_processed.csv' to 'streamlit_assets/' folder.\n",
      "Copied: pipeline_model_price.pkl to 'streamlit_assets/'\n",
      "Copied: pipeline_model_niv.pkl to 'streamlit_assets/'\n",
      "Copied: predictions_october_1_2024.csv to 'streamlit_assets/'\n",
      "Warning: features.csv does not exist and was not copied.\n",
      "Warning: target_price.csv does not exist and was not copied.\n",
      "Warning: target_niv.csv does not exist and was not copied.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "# ... [Your existing data processing and model training code] ...\n",
    "\n",
    "# After training your models and creating 'merged_data' DataFrame\n",
    "\n",
    "# 1. Ensure 'merged_data' exists\n",
    "if 'merged_data' in locals():\n",
    "    print(\"merged_data DataFrame is ready.\")\n",
    "else:\n",
    "    raise NameError(\"merged_data DataFrame is not found. Please ensure it is created before saving.\")\n",
    "\n",
    "# 2. Create 'streamlit_assets' folder\n",
    "destination_folder = 'streamlit_assets'\n",
    "current_dir = os.getcwd()\n",
    "destination_path = os.path.join(current_dir, destination_folder)\n",
    "\n",
    "if not os.path.exists(destination_path):\n",
    "    os.makedirs(destination_path)\n",
    "    print(f\"Created folder: {destination_path}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {destination_path}\")\n",
    "\n",
    "# 3. Save 'merged_data_processed.csv'\n",
    "merged_data_path = os.path.join(destination_path, 'merged_data_processed.csv')\n",
    "merged_data.to_csv(merged_data_path, index=False)\n",
    "print(f\"Saved 'merged_data_processed.csv' to '{destination_folder}/' folder.\")\n",
    "\n",
    "# 4. Save additional assets\n",
    "files_to_copy = [\n",
    "    'pipeline_model_price.pkl',\n",
    "    'pipeline_model_niv.pkl',\n",
    "    'predictions_october_1_2024.csv',\n",
    "    'features.csv',\n",
    "    'target_price.csv',\n",
    "    'target_niv.csv',\n",
    "    # Add any additional files here\n",
    "    # 'additional_file.ext',\n",
    "]\n",
    "\n",
    "for file in files_to_copy:\n",
    "    source_file = os.path.join(current_dir, file)\n",
    "    destination_file = os.path.join(destination_path, file)\n",
    "    \n",
    "    if os.path.exists(source_file):\n",
    "        shutil.copy(source_file, destination_file)\n",
    "        print(f\"Copied: {file} to '{destination_folder}/'\")\n",
    "    else:\n",
    "        print(f\"Warning: {file} does not exist and was not copied.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_data DataFrame is ready.\n",
      "Folder already exists: /Users/sravansridhar/Desktop/Edp_datathon/notebooks/streamlit_assets\n",
      "Saved 'merged_data_processed.csv' to 'streamlit_assets/' folder.\n",
      "Saved target variables to 'streamlit_assets/' folder.\n",
      "Copied: pipeline_model_price.pkl to 'streamlit_assets/'\n",
      "Copied: pipeline_model_niv.pkl to 'streamlit_assets/'\n",
      "Copied: predictions_october_1_2024.csv to 'streamlit_assets/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "# ... [Your existing data processing and model training code] ...\n",
    "\n",
    "# After training your models and creating 'merged_data' DataFrame\n",
    "\n",
    "# 1. Ensure 'merged_data' DataFrame exists\n",
    "if 'merged_data' in locals():\n",
    "    print(\"merged_data DataFrame is ready.\")\n",
    "else:\n",
    "    raise NameError(\"merged_data DataFrame is not found. Please ensure it is created before saving.\")\n",
    "\n",
    "# 2. Define features (X) and targets (y_price and y_niv)\n",
    "X = merged_data.drop(columns=['gmt_time', 'system_price_eso_outturn_gb_mwh', 'niv_outturn_ve_long_gb_mw'])\n",
    "y_price = merged_data['system_price_eso_outturn_gb_mwh']\n",
    "y_niv = merged_data['niv_outturn_ve_long_gb_mw']\n",
    "\n",
    "# 3. Verify that all columns in X are numeric\n",
    "non_numeric_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "if non_numeric_cols:\n",
    "    print(f\"Non-numeric columns found: {non_numeric_cols}\")\n",
    "    # Handle non-numeric columns if any, e.g., encoding or dropping\n",
    "    # For simplicity, let's drop them\n",
    "    X = X.drop(columns=non_numeric_cols)\n",
    "    print(f\"Dropped non-numeric columns: {non_numeric_cols}\")\n",
    "\n",
    "# 4. Create the 'streamlit_assets' folder if it doesn't exist\n",
    "destination_folder = 'streamlit_assets'\n",
    "current_dir = os.getcwd()\n",
    "destination_path = os.path.join(current_dir, destination_folder)\n",
    "\n",
    "if not os.path.exists(destination_path):\n",
    "    os.makedirs(destination_path)\n",
    "    print(f\"Created folder: {destination_path}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {destination_path}\")\n",
    "\n",
    "# 5. Save 'merged_data_processed.csv' with only features\n",
    "merged_data_processed_path = os.path.join(destination_path, 'merged_data_processed.csv')\n",
    "X.to_csv(merged_data_processed_path, index=False)\n",
    "print(f\"Saved 'merged_data_processed.csv' to '{destination_folder}/' folder.\")\n",
    "\n",
    "# 6. Save target variables\n",
    "y_price_path = os.path.join(destination_path, 'target_price.csv')\n",
    "y_niv_path = os.path.join(destination_path, 'target_niv.csv')\n",
    "\n",
    "y_price.to_csv(y_price_path, index=False)\n",
    "y_niv.to_csv(y_niv_path, index=False)\n",
    "\n",
    "print(f\"Saved target variables to '{destination_folder}/' folder.\")\n",
    "\n",
    "# 7. (Optional) Save additional assets like trained models\n",
    "files_to_copy = [\n",
    "    'pipeline_model_price.pkl',\n",
    "    'pipeline_model_niv.pkl',\n",
    "    'predictions_october_1_2024.csv',\n",
    "    # Add any additional files here\n",
    "]\n",
    "\n",
    "for file in files_to_copy:\n",
    "    source_file = os.path.join(current_dir, file)\n",
    "    destination_file = os.path.join(destination_path, file)\n",
    "    \n",
    "    if os.path.exists(source_file):\n",
    "        shutil.copy(source_file, destination_file)\n",
    "        print(f\"Copied: {file} to '{destination_folder}/'\")\n",
    "    else:\n",
    "        print(f\"Warning: {file} does not exist and was not copied.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_data DataFrame is ready.\n",
      "Folder already exists: /Users/sravansridhar/Desktop/Edp_datathon/notebooks/streamlit_assets\n",
      "Saved 'merged_data_processed.csv' to 'streamlit_assets/' folder.\n",
      "Saved target variables to 'streamlit_assets/' folder.\n",
      "Copied: pipeline_model_price.pkl to 'streamlit_assets/'\n",
      "Copied: pipeline_model_niv.pkl to 'streamlit_assets/'\n",
      "Copied: predictions_october_1_2024.csv to 'streamlit_assets/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "# ... [Your existing data processing and model training code] ...\n",
    "\n",
    "# After training your models and creating 'merged_data' DataFrame\n",
    "\n",
    "# 1. Ensure 'merged_data' DataFrame exists\n",
    "if 'merged_data' in locals():\n",
    "    print(\"merged_data DataFrame is ready.\")\n",
    "else:\n",
    "    raise NameError(\"merged_data DataFrame is not found. Please ensure it is created before saving.\")\n",
    "\n",
    "# 2. Define features (X) and targets (y_price and y_niv)\n",
    "X = merged_data.drop(columns=['gmt_time', 'system_price_eso_outturn_gb_mwh', 'niv_outturn_ve_long_gb_mw'])\n",
    "y_price = merged_data['system_price_eso_outturn_gb_mwh']\n",
    "y_niv = merged_data['niv_outturn_ve_long_gb_mw']\n",
    "\n",
    "# 3. Verify that all columns in X are numeric\n",
    "non_numeric_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "if non_numeric_cols:\n",
    "    print(f\"Non-numeric columns found: {non_numeric_cols}\")\n",
    "    # Handle non-numeric columns if any, e.g., encoding or dropping\n",
    "    # For simplicity, let's drop them\n",
    "    X = X.drop(columns=non_numeric_cols)\n",
    "    print(f\"Dropped non-numeric columns: {non_numeric_cols}\")\n",
    "\n",
    "# 4. Create the 'streamlit_assets' folder if it doesn't exist\n",
    "destination_folder = 'streamlit_assets'\n",
    "current_dir = os.getcwd()\n",
    "destination_path = os.path.join(current_dir, destination_folder)\n",
    "\n",
    "if not os.path.exists(destination_path):\n",
    "    os.makedirs(destination_path)\n",
    "    print(f\"Created folder: {destination_path}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {destination_path}\")\n",
    "\n",
    "# 5. Save 'merged_data_processed.csv' with only features\n",
    "merged_data_processed_path = os.path.join(destination_path, 'merged_data_processed.csv')\n",
    "X.to_csv(merged_data_processed_path, index=False)\n",
    "print(f\"Saved 'merged_data_processed.csv' to '{destination_folder}/' folder.\")\n",
    "\n",
    "# 6. Save target variables\n",
    "y_price_path = os.path.join(destination_path, 'target_price.csv')\n",
    "y_niv_path = os.path.join(destination_path, 'target_niv.csv')\n",
    "\n",
    "y_price.to_csv(y_price_path, index=False)\n",
    "y_niv.to_csv(y_niv_path, index=False)\n",
    "\n",
    "print(f\"Saved target variables to '{destination_folder}/' folder.\")\n",
    "\n",
    "# 7. (Optional) Save additional assets like trained models\n",
    "files_to_copy = [\n",
    "    'pipeline_model_price.pkl',\n",
    "    'pipeline_model_niv.pkl',\n",
    "    'predictions_october_1_2024.csv',\n",
    "    # Add any additional files here\n",
    "]\n",
    "\n",
    "for file in files_to_copy:\n",
    "    source_file = os.path.join(current_dir, file)\n",
    "    destination_file = os.path.join(destination_path, file)\n",
    "    \n",
    "    if os.path.exists(source_file):\n",
    "        shutil.copy(source_file, destination_file)\n",
    "        print(f\"Copied: {file} to '{destination_folder}/'\")\n",
    "    else:\n",
    "        print(f\"Warning: {file} does not exist and was not copied.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'gmt_time' column successfully excluded from 'merged_data_processed.csv'.\n",
      "All columns in 'merged_data_processed.csv' are numeric.\n",
      "'target_price.csv' loaded successfully.\n",
      "'target_niv.csv' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the Streamlit assets folder\n",
    "assets_path = 'streamlit_assets'\n",
    "\n",
    "# Verify 'merged_data_processed.csv'\n",
    "merged_data_processed_path = os.path.join(assets_path, 'merged_data_processed.csv')\n",
    "merged_data_processed = pd.read_csv(merged_data_processed_path)\n",
    "\n",
    "# Check if 'gmt_time' is present\n",
    "if 'gmt_time' in merged_data_processed.columns:\n",
    "    print(\"Error: 'gmt_time' column is present in 'merged_data_processed.csv'. It should be excluded.\")\n",
    "else:\n",
    "    print(\"'gmt_time' column successfully excluded from 'merged_data_processed.csv'.\")\n",
    "\n",
    "# Verify that all columns are numeric\n",
    "non_numeric_cols = merged_data_processed.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "if non_numeric_cols:\n",
    "    print(f\"Non-numeric columns found: {non_numeric_cols}\")\n",
    "else:\n",
    "    print(\"All columns in 'merged_data_processed.csv' are numeric.\")\n",
    "\n",
    "# Verify target files\n",
    "y_price_path = os.path.join(assets_path, 'target_price.csv')\n",
    "y_niv_path = os.path.join(assets_path, 'target_niv.csv')\n",
    "\n",
    "if os.path.exists(y_price_path):\n",
    "    y_price = pd.read_csv(y_price_path)\n",
    "    print(\"'target_price.csv' loaded successfully.\")\n",
    "else:\n",
    "    print(\"Error: 'target_price.csv' not found.\")\n",
    "\n",
    "if os.path.exists(y_niv_path):\n",
    "    y_niv = pd.read_csv(y_niv_path)\n",
    "    print(\"'target_niv.csv' loaded successfully.\")\n",
    "else:\n",
    "    print(\"Error: 'target_niv.csv' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'merged_data_processed.csv' successfully.\n",
      "Loaded 'target_price.csv' successfully.\n",
      "Loaded 'target_niv.csv' successfully.\n",
      "Loaded 'pipeline_model_price.pkl' successfully.\n",
      "Loaded 'pipeline_model_niv.pkl' successfully.\n",
      "\n",
      "Evaluating System Price Model:\n",
      "[LightGBM] [Info] [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.009515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7450\n",
      "[LightGBM] [Info] Total Bins 7424\n",
      "[LightGBM] [Info] Number of data points in the train set: 39424, number of used features: 34\n",
      "[LightGBM] [Info] Number of data points in the train set: 19712, number of used features: 33\n",
      "[LightGBM] [Info] [LightGBM] [Info] Start training from score 57.334813Start training from score 47.721245\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 47.174889\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 78848, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 74.514280\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7463\n",
      "[LightGBM] [Info] Number of data points in the train set: 98560, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 90.913762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7426\n",
      "[LightGBM] [Info] Number of data points in the train set: 15769, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 57.254488\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7418\n",
      "[LightGBM] [Info] Number of data points in the train set: 15769, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 58.988038\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7409\n",
      "[LightGBM] [Info] Number of data points in the train set: 15770, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 57.578630\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7407\n",
      "[LightGBM] [Info] Number of data points in the train set: 15770, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 55.883148\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7418\n",
      "[LightGBM] [Info] Number of data points in the train set: 15770, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 56.969860\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 31539, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 46.104988\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7446\n",
      "[LightGBM] [Info] Number of data points in the train set: 31539, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.713049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 31539, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 46.849822\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7438\n",
      "[LightGBM] [Info] Number of data points in the train set: 31539, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.248714\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 31540, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 50.689560\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.240258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 45.172416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.434509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 51.528501\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 44.498720\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 63078, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 78.900525\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 63078, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 82.040774\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 63078, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 85.114394\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7454\n",
      "[LightGBM] [Info] Number of data points in the train set: 63079, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 77.024114\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 63079, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 49.491952\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 78848, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 99.308499\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7463\n",
      "[LightGBM] [Info] Number of data points in the train set: 78848, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 104.115283\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 78848, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 102.121658\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 78848, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 74.509088\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 78848, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 74.514280\n",
      "Training RMSE: 28.4530  15.2914\n",
      "Validation RMSE: 48.3644  28.8368\n",
      "\n",
      "Evaluating NIV Model:\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7424\n",
      "[LightGBM] [Info] Number of data points in the train set: 19712, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 140.729460\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7450\n",
      "[LightGBM] [Info] Number of data points in the train set: 39424, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 91.653802\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 59136, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 29.661958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 78848, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 10.034320\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7463\n",
      "[LightGBM] [Info] Number of data points in the train set: 98560, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 11.713706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7426\n",
      "[LightGBM] [Info] Number of data points in the train set: 15769, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 143.722139\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7418\n",
      "[LightGBM] [Info] Number of data points in the train set: 15769, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 128.342307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7409\n",
      "[LightGBM] [Info] Number of data points in the train set: 15770, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 147.462923\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7407\n",
      "[LightGBM] [Info] Number of data points in the train set: 15770, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 155.065096\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7418\n",
      "[LightGBM] [Info] Number of data points in the train set: 15770, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 129.054238\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 31539, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 74.659568\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7446\n",
      "[LightGBM] [Info] Number of data points in the train set: 31539, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 89.947225\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 31539, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 75.201382\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7438\n",
      "[LightGBM] [Info] Number of data points in the train set: 31539, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 93.088044\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7441\n",
      "[LightGBM] [Info] Number of data points in the train set: 31540, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 125.371722\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47308, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 1.005892\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.885601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.568355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 56.609920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7452\n",
      "[LightGBM] [Info] Number of data points in the train set: 47309, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 60.239415\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 63078, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -19.721603\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 63078, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -17.880287\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 63078, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 30.045585\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7454\n",
      "[LightGBM] [Info] Number of data points in the train set: 63079, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 36.464288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 63079, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 21.263019\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 78848, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -20.540232\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7463\n",
      "[LightGBM] [Info] Number of data points in the train set: 78848, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 3.997597\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7457\n",
      "[LightGBM] [Info] Number of data points in the train set: 78848, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 38.222566\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7466\n",
      "[LightGBM] [Info] Number of data points in the train set: 78848, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 26.854281\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 78848, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 10.034320\n",
      "Training RMSE: 92.3855  18.4901\n",
      "Validation RMSE: 116.0066  35.4421\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_validate, TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "import os\n",
    "\n",
    "# Define a function to calculate RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Create a scorer for RMSE\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "# Define the path to the Streamlit assets folder\n",
    "assets_path = 'streamlit_assets'\n",
    "\n",
    "# Load the preprocessed features\n",
    "data_path = os.path.join(assets_path, 'merged_data_processed.csv')\n",
    "if os.path.exists(data_path):\n",
    "    X = pd.read_csv(data_path)\n",
    "    print(\"Loaded 'merged_data_processed.csv' successfully.\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"'{data_path}' not found. Please ensure it is saved correctly.\")\n",
    "\n",
    "# Load target variables\n",
    "y_price_path = os.path.join(assets_path, 'target_price.csv')\n",
    "y_niv_path = os.path.join(assets_path, 'target_niv.csv')\n",
    "\n",
    "if os.path.exists(y_price_path):\n",
    "    y_price = pd.read_csv(y_price_path)['system_price_eso_outturn_gb_mwh']\n",
    "    print(\"Loaded 'target_price.csv' successfully.\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"'{y_price_path}' not found. Please ensure it is saved correctly.\")\n",
    "\n",
    "if os.path.exists(y_niv_path):\n",
    "    y_niv = pd.read_csv(y_niv_path)['niv_outturn_ve_long_gb_mw']\n",
    "    print(\"Loaded 'target_niv.csv' successfully.\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"'{y_niv_path}' not found. Please ensure it is saved correctly.\")\n",
    "\n",
    "# Load the trained models\n",
    "model_price_path = os.path.join(assets_path, 'pipeline_model_price.pkl')\n",
    "model_niv_path = os.path.join(assets_path, 'pipeline_model_niv.pkl')\n",
    "\n",
    "if os.path.exists(model_price_path):\n",
    "    best_model_price_loaded = joblib.load(model_price_path)\n",
    "    print(\"Loaded 'pipeline_model_price.pkl' successfully.\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"'{model_price_path}' not found. Please ensure it is saved correctly.\")\n",
    "\n",
    "if os.path.exists(model_niv_path):\n",
    "    best_model_niv_loaded = joblib.load(model_niv_path)\n",
    "    print(\"Loaded 'pipeline_model_niv.pkl' successfully.\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"'{model_niv_path}' not found. Please ensure it is saved correctly.\")\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Function to evaluate a model and print RMSE scores\n",
    "def evaluate_model(model, X, y, model_name):\n",
    "    print(f\"\\nEvaluating {model_name} Model:\")\n",
    "    \n",
    "    try:\n",
    "        # Perform cross-validation\n",
    "        cv_results = cross_validate(\n",
    "            model, \n",
    "            X, \n",
    "            y, \n",
    "            cv=tscv, \n",
    "            scoring=rmse_scorer, \n",
    "            return_train_score=True,\n",
    "            n_jobs=-1,  # Utilize all available CPU cores\n",
    "            error_score='raise'  # Raise exceptions for debugging\n",
    "        )\n",
    "        \n",
    "        # Extract training and validation RMSE scores\n",
    "        train_rmse = -cv_results['train_score']  # Multiply by -1 to get positive RMSE\n",
    "        val_rmse = -cv_results['test_score']\n",
    "        \n",
    "        # Calculate mean and standard deviation\n",
    "        train_rmse_mean = train_rmse.mean()\n",
    "        train_rmse_std = train_rmse.std()\n",
    "        val_rmse_mean = val_rmse.mean()\n",
    "        val_rmse_std = val_rmse.std()\n",
    "        \n",
    "        # Print the results\n",
    "        print(f\"Training RMSE: {train_rmse_mean:.4f}  {train_rmse_std:.4f}\")\n",
    "        print(f\"Validation RMSE: {val_rmse_mean:.4f}  {val_rmse_std:.4f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during cross-validation for {model_name}: {e}\")\n",
    "\n",
    "# Evaluate the System Price model\n",
    "evaluate_model(best_model_price_loaded, X, y_price, 'System Price')\n",
    "\n",
    "# Evaluate the NIV model\n",
    "evaluate_model(best_model_niv_loaded, X, y_niv, 'NIV')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
